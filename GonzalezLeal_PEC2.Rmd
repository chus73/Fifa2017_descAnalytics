---
title: "Analítica descriptiva e inferencial del Fifa 2017"
author: "Jesús González"
date: "23/4/2021"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
    
  pdf_document:
    highlight: zenburn
    toc: yes
    
  word_document: default
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

------------------------------------------------------------------------

```{r}
#install.packages("tidyverse")
library(tidyverse) 
library(stringr) 
library(dplyr) 
library(lubridate) 
library(ggplot2)
library(gridExtra)
library(grid)
library(ggplot2)
library(lattice)
library(kableExtra)

# Winsor package
# https://www.rdocumentation.org/packages/psych/versions/2.0.12/topics/winsor

#install.packages('psych')

#library(psych)

#ggbiplot package

#https://www.rdocumentation.org/packages/ggbiplot/versions/0.55
#https://www.rdocumentation.org/packages/ggbiplot/versions/0.55/topics/ggbiplot

#library(devtools)
#install_github("vqv/ggbiplot")
#library(ggbiplot)


```

# Introducción

# Lectura del fichero

```{r}
fifa.df <- read.csv(file="./Data/fifa_clean.csv", encoding = "UTF8", stringsAsFactors = F)
paste0("Número de observaciones: ", nrow(fifa.df),". Número de variables: ", ncol(fifa.df))
```

Verificamos si existen duplicados en el identificador.

```{r}
if (length(fifa.df$ID) == length(unique(fifa.df$ID))) {
  print("No hay diferencias en el ID")} else {print("Existen diferencias en el ID")}
```

Convertimos a factor los literales.

```{r}
column_name <- c('Nationality','National_Position', 'Club', 'Club_Position', 'Preffered_Foot', 'Preffered_Position', 'Work_Rate')
for (col in column_name) {
  fifa.df[,col] <- factor(fifa.df[,col])
}
```

Para el estudio, se va a investigar las variables: Rating, Ball_Control
y Dribbling. Se va a realizar una subselección.

```{r}
column_name <- c('ID', 'Name', 'Nationality', 'Preffered_Foot', 'Club_Position', 'Rating', 'Ball_Control', 'Dribbling' )
fifa.df.sub <- fifa.df[, column_name]
```

Revisamos las primeras líneas de las observaciones cargadas.

```{r}
head(fifa.df.sub, 5)
```

Revisamos las estadísticas básicas.

```{r}
summary(fifa.df.sub)
```

# Rating de los jugadores

La variable Rating muestra la puntuación del jugador.

## Análisis visual

A continuación se va a mostrar visualmente que distribución sigue esta
variable.

```{r}
ggplot(fifa.df.sub, aes(x= Rating)) + 
  geom_histogram(binwidth = 1, fill="#69b3a2", color="#e9ecef", alpha=0.9) + 
  geom_vline(xintercept = mean(fifa.df.sub$Rating), colour="blue", linetype = "longdash")
```

Podemos comprobar como la variable puntuación sigue una distribución
normal y prácticamente simétrica. Se muestra con la línea azúl que
indica la media, viéndose que sigue una distribución casi centrada en la
media.

```{r}
summary(fifa.df.sub$Rating)
```

Efectivamente, esta simetría la podemos comprobar al fijarnos en los
valores de media y mediana, podemos ver que se encuentran prácticamente
solapadas.

Esto también lo podemos ver con un gráfico Q-Q

```{r}
qqnorm(fifa.df.sub$Rating)
qqline(fifa.df.sub$Rating)
```

En donde vemos que el error de los puntos de observación con respecto a
la recta es mínimo.

## Intervalo de confianza

Vamos a establecer el intervalo de confianza de esta variable a partir
de su media, y calculando su desviación estándar.

```{r}
NC <- 0.95
n <- length(fifa.df.sub$Rating)
print(paste('Número de observaciones: ', n))

# Cálculo de la desviación estándar
sd <- sd(fifa.df.sub$Rating)

# Cálculo de z_alpha/2
#z_alpha_1_2 <- qnorm(0.025)

alpha <- 1-NC
alpha
SE <- sd / sqrt(n)
SE
z <- qnorm(alpha/2, lower.tail = F)
z
L <- mean(fifa.df.sub$Rating) - z*SE
U <- mean(fifa.df.sub$Rating) + z*SE
print(paste('Los niveles de confianza se encuentran definidos en el rango [',round(L, 2),', ', round(U, 2), '] para un nivel de confianza del ', NC*100, '%')) 

```

# Diferencias entre jugadores

En este apartado, se va a comprobar si los jugadores zurdos tienen mejor
control de la pelota (variable Ball_Control), valoración (Rating) y
mejor Dribbling que lo diestros. Como paso previo vamos a diferenciar en
dos subsets a los jugadores zurdos de los diestros, eliminando a los
porteros (Código GK de la variable Club_Position).

```{r}

left_gamers <- fifa.df.sub %>% filter(Club_Position!='GK' & Preffered_Foot=='Left') %>% select('ID', 'Rating', 'Ball_Control', 'Dribbling')

right_gamers <- fifa.df.sub %>% filter(Club_Position!='GK' & Preffered_Foot=='Right') %>% select('ID', 'Rating', 'Ball_Control', 'Dribbling')
```

## Pregunta de investigación

La pregunta que se quiere responder es si los valores de las tres
variables a estudiar son significativamente mayores entre los jugadores
zurdos y los diestros. Estamos ante un caso de contraste unilateral de
dos muestras poblacionales independientes.

Por tanto, definiendo la hipótesis nula como que no hay diferencias por
el hecho de ser diestros o zurdos, tendríamos que la hipótesis
alternativa es aquella en la que los zurdos consiguen mejor puntuación
en las tres variables.

Distribución unilateral por la derecha.

## Representación visual

```{r}
left_gamers$type <- 'left'
right_gamers$type <- 'right'
columns_names <- c('Rating', 'Ball_Control', 'Dribbling', 'type')
data <- merge(x=left_gamers[, columns_names], y =right_gamers[,columns_names], all=T )
```

```{r}

p1 <- ggplot(data=data,aes(x=type, y=Rating,color=type))+geom_boxplot()
p2 <- ggplot(data=data,aes(x=type, y=Ball_Control,color=type))+geom_boxplot()
p3 <- ggplot(data=data,aes(x=type, y=Dribbling,color=type))+geom_boxplot()
grid.arrange(p1, p2, p3, ncol=3, top= 'Boxplox Compare main attributes')

```

## Hipótesis nula y alternativa

A partir de la pregunta realizada definimos la hipótesis nula como que
no hay diferencias por el hecho de ser diestros o zurdos. En
contraposición, tendríamos que la hipótesis alternativa es aquella en la
que los zurdos consiguen mejor puntuación en las tres variables.

Planteado de un modo más matemático:

$$
\left\{
\begin{array}{ll}
H_{0}: &  \mu_{left} <= \mu_{right}\\
H_{1}: & \mu_{left} > \mu_{right}
\end{array}
\right.
$$

Para cada una de las tres variables observadas, Rating, Ball control y
Dribbling, y dentro del intervalo de confianza (NC) del 95 %.

## Método

En este apartado vamos a responder una serie de cuestiones que nos
ayudarán a escoger el método adecuado para validar la hipótesis
planteada.

-   **Tipo de contraste**. En este estudio estamos valorando dos
    muestras independientes de tamaños diferentes. Para ello
    realizaremos un contraste sobre la media.

-   **Normalidad de la muestra**: El número de muestras es
    suficientemente grande como para poder aplicar el [teorema del
    límite central]{.ul} (TLC) que dice que la media poblacional **se
    comporta** como una normal si el número de muestras es
    suficientemente grande, estimándose como suficiente para la gran
    mayoría de los casos cuando se superan las 30 observaciones.

**Propiedades del test a aplicar**:

-   **Test paramétrico o No paramétrico**

-   **Test bilateral o Unilateral:** Si examinamos la hipótesis
    alternativa ($H_1$), estamos hablando de un contraste unilateral por
    la derecha.

-   **Homocedasticidad o heterocedasticidad:** Para resolver este
    parámetro nos fijaremos en la variabilidad de las muestras aplicando
    un F test.

```{r  echo=FALSE, messages=FALSE}
columns_names <- c('Rating', 'Ball_Control', 'Dribbling') 
var_table <- data.frame(matrix(ncol=5, nrow = 0)) 
column_names_table <- c('Variable', 'F test', 'p valor', 'NC1', 'NC2')
for (col in columns_names){
  out <- var.test(x=left_gamers[,col], y=right_gamers[,col])
  var_table <- rbind(var_table, c(col, round(out$statistic,4), out$p.value, round(out$conf.int[1],4), round(out$conf.int[2],4)))
}
colnames(var_table) <- column_names_table
var_table
```

El test F de Snedecor establece como hipótesis nula la homogeneidad de
las varianzas. Los p-valores encontrados nos indican que podemos
rechazar la \$H\_{0}\$, encontrándonos con que las muestras de las tres
variables observadas presentan **heterocedasticidad**.

## Cálculos

Ahora procederemos a calcular el estadístico de contraste, el valor
crítico y el valor de $p$ .

```{r}
# Definimos el intervalo de confianza
NC <- 0.95
alpha <- 1-NC
# Cálculo del valor crítico
valor_critico <- qnorm(alpha)
# Cálculo de las medias
mean_left <- mean(data[data$type == 'left', 'Rating'])
mean_right <- mean(data[data$type == 'right', 'Rating'])
# Desviación estándar
sd_left <- sd(data[data$type == 'left', 'Rating'])
sd_right <- sd(data[data$type == 'right', 'Rating'])
# Número de muestras
n_left <- length(data[data$type == 'left', 'Rating'])
n_right <- length(data[data$type == 'right', 'Rating'])

# Cálculo del estimador
t <- (mean_left - mean_right) / sqrt((sd_left^2/n_left) + (sd_right^2/n_right))

```

```{r}
t_2_sample_unknow_var <- function(df, column_name, NC){
  # El intervalo de confianza es dado (95% por defecto)

  alpha <- 1-NC
  # Cálculo del valor crítico
  vc <- qnorm(alpha)
  # Cálculo de las medias
  mean_left <- mean(df[df$type == 'left', column_name])
  mean_right <- mean(df[df$type == 'right', column_name])
  # Desviación estándar
  sd_left <- sd(df[df$type == 'left', column_name])
  sd_right <- sd(df[df$type == 'right', column_name])
  # Número de muestras
  n_left <- length(df[df$type == 'left', column_name])
  n_right <- length(df[df$type == 'right', column_name])

  # Cálculo del estimador
  t <- (mean_left - mean_right) / sqrt((sd_left^2/n_left) + (sd_right^2/n_right))  
  # Resultado
  return(c(column_name, t, abs(vc)))
}
column_names <- c('Rating', 'Ball_Control', 'Dribbling')
t2_sample_table <- data.frame(matrix(ncol=3, nrow = 0))
for (col in column_names){
  out <- t_2_sample_unknow_var(data, col, 0.95)
  t2_sample_table <- rbind(t2_sample_table, out)
}
names(t2_sample_table) <- c("Variable", "t-valor", "valor_critico")
t2_sample_table
```

```{r}
t.test(data[data$type == 'left', 'Rating'], 
       data[data$type == 'right', 'Rating'],
       alternative= "greater",
       var.equal= F)
```

## Tabla de resultados

Mostramos los resultados

```{r}
t2_sample_table %>% kable() %>% kable_styling()
```

## Interpretación

Como podemos interpretar de los resultados, en las tres variables
estudiadas el valor observado (t-valor) es mayor que el valor crítico lo
que permite rechazar la hipótesis nula aceptando que [los jugadores
zurdos obtienen mejores puntuaciones que los diestros]{.ul} para estas
variables.

# Comparación por pares

## Jugador más similar

## Muestras

## Hipótesis nula y alternativa

## Método

## Cálculos

## Interpretación

## Reflexión

# Comparación entre clubes

## Hipótesis nula y alternativa

## Método

## Cálculos

## Resultados e interpretación

# Resumen ejecutivo
