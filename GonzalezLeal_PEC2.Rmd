---
title: "Analítica descriptiva e inferencial del Fifa 2017"
author: "Jesús González"
date: "23/4/2021"
output:
  pdf_document:
    
    highlight: zenburn
    toc: yes
  html_document:
    
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
  word_document: default
editor_options: 
  markdown: 
    wrap: 72
---

```{r kntir options, message=FALSE, warning=FALSE, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#options(encoding = "UTF-8")
```

------------------------------------------------------------------------

```{r Librerias, message=FALSE, warning=FALSE}
library(ggplot2)
library(dplyr) 
library(gridExtra)
library(kableExtra)

#library(tidyverse) 
#library(stringr) 

#library(lubridate) 


#library(grid)

#library(lattice)


```

# Introducción

Esta actividad se centra en el análisis estadístico descriptivo e
inferencial del conjunto de datos del videojuego Fifa 2017, así como
estadísticas reales de jugadores de fútbol. El conjunto inicial contiene
más de 17.500 registros repartidos en 53 variables.

Se parte de un fichero, fifa_clean.csv, en donde ya se ha realizado
tareas de limpieza y consolidación del dato. En esta actividad, nos
interesa investigar la puntuación del jugador (Variable Rating) y otras
variables como el control de la pelota (variable Ball_Control) y la
técnica del jugador (variable Dribbling). Se asume que los datos
contenidos en el fichero, *constituyen una muestra representativa de los
jugadores de la última década (población).*

# Lectura del fichero

```{r}
fifa.df <- read.csv(file="./Data/fifa_clean.csv", encoding = "UTF8", stringsAsFactors = F, header = T)
paste0("Número de observaciones: ", nrow(fifa.df),". Número de variables: ", ncol(fifa.df))
```

Verificamos si existen duplicados en el identificador.

```{r}
if (length(fifa.df$ID) == length(unique(fifa.df$ID))) {
  print("No hay diferencias en el ID")} else {print("Existen diferencias en el ID")}
```

Convertimos a factor los literales.

```{r}
column_name <- c('Nationality','National_Position', 'Club', 'Club_Position', 'Preffered_Foot', 'Preffered_Position', 'Work_Rate')
for (col in column_name) {
  fifa.df[,col] <- factor(fifa.df[,col])
}
```

Para el estudio, se va a investigar las variables: *Rating*,
*Ball_Control* y *Dribbling*, por ello se va a realizar una subselección
del dataset original, para quedarnos con las que necesitamos para
nuestro estudio.

```{r}
column_name <- c('ID', 'Name', 'Nationality', 'Preffered_Foot', 'Club_Position', 'Rating', 'Ball_Control', 'Dribbling' )
fifa.df.sub <- fifa.df[, column_name]
```

Con el fin de poder comprobar si los datos se han cargado correctamente,
revisamos las primeras líneas de las observaciones cargadas.

```{r}
head(fifa.df.sub, 5)
```

A continuación, se expone una descripción de las variables cargadas:

-   **Name**: Nombre del jugador. Literal.

-   **Nationality**: Nacionalidad del jugador. Se ha convertido a
    factor.

-   **Preffered_Foot**: Variable binaria que describe si el jugador es
    diestro (valor right) o zurdo (valor left).

-   **Clup_Position**: Posición de juego del jugador en club.

-   **Rating**: Valoración global de juego del jugador. Tiene un rango
    de valores de 0 a 100.

-   **Ball_Control**: Valoración del control del balón del jugador.
    Tiene un rango de valores de 0 a 100.

-   **Dribbling**: Valoración de la técnica del jugador.Tiene un rango
    de valores de 0 a 100.

Revisamos las estadísticas básicas.

```{r}
summary(fifa.df.sub)
```

En la variable Nationality podemos ver que los grupos de jugadores que
dominan el dataset (mayor frecuencia) son de nacionalidad inglesa,
argentina y española. Aunque en Otros, tenemos una agrupación mayor que
el top 6 de nacionalidades que aparecen descritas, por lo que no hay
relevancia estadística.

En cambio, Preffered_Foot si tenemos un balanceo hacia jugadores
diestros en una proporción de 3 a 1 que se tiene que tener en cuenta
respecto al sesgo que puede plantear.

Para Club_Position, el valor Sub es mayoritario.

En cuanto a las tres variables cuantitativas, Rating, Ball_control y
Dribbling, la primera de ellas, presenta un buen centrado de la
población respecto a la media, cosa que no ocurre en las otras dos, que
se encuentra desbalanceadas hacia la izquierda.

Vamos a estudiar estas variables con más atención.

# Rating de los jugadores

En el primer apartado de este estudio, interesa investigar la variable
Rating, que muestra la puntuación del jugador.

## Análisis visual

A continuación se va a mostrar visualmente que distribución sigue esta
variable.

```{r}
ggplot(fifa.df.sub, aes(x= Rating)) + 
  geom_histogram(binwidth = 1, fill="#69b3a2", color="#e9ecef", alpha=0.9) + 
  geom_vline(xintercept = mean(fifa.df.sub$Rating), colour="blue", linetype = "longdash")
```

De la observación de la salida del histograma, podemos comprobar como la
variable puntuación sigue una distribución muy similar a la normal y
prácticamente simétrica. Se muestra con la línea azúl de referencia que
indica la media de la serie. Visualmente se comprueba que la
distribución se encuentra casi centrada en la media.

```{r}
summary(fifa.df.sub$Rating)
```

Efectivamente, esta simetría la podemos comprobar numéricamente al
fijarnos en los valores de media y mediana, podemos ver que se
encuentran prácticamente solapadas.

Podemos apoyar aún más nuestra afirmación realizando un gráfico Q-Q para
esta variable.

```{r}
qqnorm(fifa.df.sub$Rating)
qqline(fifa.df.sub$Rating)
```

En donde vemos que el error de los puntos de observación con respecto a
la recta es mínimo y localizados en los extremos.

## Intervalo de confianza

Vamos a establecer el intervalo de confianza de esta variable a partir
de su media, y calculando su desviación estándar.

```{r}
NC <- 0.95
n <- length(fifa.df.sub$Rating)
print(paste('Número de observaciones: ', n))

# Cálculo de la desviación estándar
sd <- sd(fifa.df.sub$Rating)

# Cálculo de z_alpha/2
#z_alpha_1_2 <- qnorm(0.025)

alpha <- 1-NC
SE <- sd / sqrt(n)
z <- qnorm(alpha/2, lower.tail = F)
L <- mean(fifa.df.sub$Rating) - z*SE
U <- mean(fifa.df.sub$Rating) + z*SE
print(paste('Los niveles de confianza se encuentran definidos en el rango [',round(L, 2),', ', round(U, 2), '] para un nivel de confianza del ', NC*100, '%')) 

```

Para acabar de confirmar la normalidad de la variable, a más a más de
las observaciones de la serie, muy superior en número a los 30 valores,
nos podemos apoyar en el **teorema del límite centrar** (TLC). Por lo
tanto, y debido a que la distribución sigue una normal, por simetría, el
nivel crítico se calcula con la mitad de alfa para un nivel de confianza
(NC) del 95%.

# Diferencias entre jugadores

En este apartado, se va a comprobar si [los jugadores zurdos tienen
mejor control de la pelota (variable Ball_Control), valoración (Rating)
y mejor Dribbling que lo diestros]{.ul}. Como paso previo vamos a
diferenciar en dos subsets a los jugadores zurdos de los diestros,
eliminando a los porteros (Código GK de la variable Club_Position).

```{r}

left_gamers <- fifa.df.sub %>% filter(Club_Position!='GK' & Preffered_Foot=='Left') %>% select('ID', 'Rating', 'Ball_Control', 'Dribbling')

right_gamers <- fifa.df.sub %>% filter(Club_Position!='GK' & Preffered_Foot=='Right') %>% select('ID', 'Rating', 'Ball_Control', 'Dribbling')
```

## Pregunta de investigación

La pregunta que se quiere responder es si los valores de las tres
variables a estudiar son **significativamente mayores** entre los
jugadores zurdos y los diestros. Estamos ante un caso de contraste
unilateral de dos muestras poblacionales independientes.

Por tanto, definiendo la hipótesis nula como que no hay diferencias por
el hecho de ser diestros o zurdos, tendríamos que la hipótesis
alternativa es aquella en la que los zurdos consiguen mejor puntuación
en las tres variables.

Distribución unilateral por la derecha.

## Representación visual

Veamos el comportamiento de las tres variables del estudio en función de
si los jugadores son zurdos o diestros

```{r}
left_gamers$type <- 'left'
right_gamers$type <- 'right'
columns_names <- c('Rating', 'Ball_Control', 'Dribbling', 'type')
data <- merge(x=left_gamers[, columns_names], y =right_gamers[,columns_names], all=T )
```

```{r}

p1 <- ggplot(data=data,aes(x=type, y=Rating,color=type))+geom_boxplot()
p2 <- ggplot(data=data,aes(x=type, y=Ball_Control,color=type))+geom_boxplot()
p3 <- ggplot(data=data,aes(x=type, y=Dribbling,color=type))+geom_boxplot()
grid.arrange(p1, p2, p3, ncol=3, top= 'Boxplox Compare main attributes')

```

A nivel general, vemos como en el caso de los zurdos, las medianas de
las tres variables están por encima en puntuación que la de los diestros
(valor superior indica mejor puntuación). Es destacable también, la
presencia de valores extremos inferiores para el control de la pelota y
del juego, sobretodo en jugadores zurdos. Para estas dos variables,
tenemos también valores extremos superiores para los jugadores zurdos,
lo que indica que hay jugadores zurdos con muy buenas puntuaciones en
control del balón y juego. En cuanto al rating, los valores extremos
superiores e inferiores se encuentran equilibrados para los dos tipos de
jugadores.

## Hipótesis nula y alternativa

A partir de la pregunta realizada definimos la hipótesis nula como que
no hay diferencias por el hecho de ser diestros o zurdos. En
contraposición, tendríamos que la hipótesis alternativa es aquella en la
que los zurdos consiguen mejor puntuación en las tres variables.

Planteado de un modo más matemático:

$$
\left\{
\begin{array}{ll}
H_{0}: &  \mu_{left} <= \mu_{right}\\
H_{1}: & \mu_{left} > \mu_{right}
\end{array}
\right.
$$

Para cada una de las tres variables observadas, Rating, Ball control y
Dribbling, y [dentro del intervalo de confianza (NC) del 95 %]{.ul}.

## Método

En este apartado vamos a responder una serie de cuestiones que nos
ayudarán a escoger el método adecuado para validar la hipótesis
planteada.

-   **Tipo de contraste**. En este estudio estamos valorando dos
    muestras independientes de tamaños diferentes. Para ello
    realizaremos un **contraste sobre la media**.

-   **Normalidad de la muestra**: El número de muestras es
    suficientemente grande como para poder aplicar el [teorema del
    límite central]{.ul} (TLC) que dice que la media poblacional **se
    comporta** como una normal si el número de muestras es
    suficientemente grande, estimándose como suficiente para la gran
    mayoría de los casos cuando se superan las 30 observaciones.

**Propiedades del test a aplicar**:

-   **Test paramétrico o No paramétrico.** La normalidad de la muestra
    justificadas en el punto anterior nos permite afirmar que podemos
    aplicar un test paramétrico.

-   **Test bilateral o Unilateral:** Si examinamos la hipótesis
    alternativa ($H_1$), estamos hablando de un contraste [unilateral
    por la derecha]{.ul}.

-   **Homocedasticidad o heterocedasticidad:** Para resolver este
    parámetro nos fijaremos en la variabilidad de las muestras aplicando
    un F test.

```{r echo=TRUE, messages=FALSE}
columns_names <- c('Rating', 'Ball_Control', 'Dribbling') 
var_table <- data.frame(matrix(ncol=5, nrow = 0)) 
column_names_table <- c('Variable', 'F test', 'p valor', 'NC1', 'NC2')
for (col in columns_names){
  out <- var.test(x=left_gamers[,col], y=right_gamers[,col])
  var_table <- rbind(var_table, c(col, round(out$statistic,4), out$p.value, round(out$conf.int[1],4), round(out$conf.int[2],4)))
}
colnames(var_table) <- column_names_table
var_table
```

El test **F de Snedecor** establece como hipótesis nula la homogeneidad
de las varianzas. Los p-valores encontrados nos indican que podemos
rechazar la $H_{0}$, encontrándonos con que las muestras de las tres
variables observadas presentan **heterocedasticidad**.

## Cálculos

Ahora procederemos a calcular el estadístico de contraste, el valor
crítico y el valor de $p$, teniendo en cuenta todo las características
de la muestra que hemos visto anteriormente (Contraste de dos muestras
independientes sobre la media con varianzas desconocidas).

```{r}
t_2_sample_unknow_var <- function(df, column_name, NC){
  # El intervalo de confianza es dado (95% por defecto)

  alpha <- 1-NC
  # Cálculo del valor crítico
  vc <- qnorm(alpha)
  # Cálculo de las medias
  mean_left <- mean(df[df$type == 'left', column_name])
  mean_right <- mean(df[df$type == 'right', column_name])
  # Desviación estándar
  sd_left <- sd(df[df$type == 'left', column_name])
  sd_right <- sd(df[df$type == 'right', column_name])
  # Número de muestras
  n_left <- length(df[df$type == 'left', column_name])
  n_right <- length(df[df$type == 'right', column_name])

  # Cálculo del estimador
  t <- (mean_left - mean_right) / sqrt((sd_left^2/n_left) + (sd_right^2/n_right))  
  # Resultado
  return(c(column_name, t, abs(vc)))
}
column_names <- c('Rating', 'Ball_Control', 'Dribbling')
t2_sample_table <- data.frame(matrix(ncol=3, nrow = 0))
for (col in column_names){
  out <- t_2_sample_unknow_var(data, col, 0.95)
  t2_sample_table <- rbind(t2_sample_table, out)
}
names(t2_sample_table) <- c("Variable", "t-valor", "valor_critico")

```

## Tabla de resultados

Mostramos los resultados para las tres variables de la muestra de
jugadores

```{r}
t2_sample_table %>% kable() %>% kable_styling()
```

## Interpretación

Como podemos observar de los resultados de la tabla anterior, en las
tres variables estudiadas el valor observado (t-valor) es mayor que el
valor crítico

      t valor > valor crítico

lo que permite rechazar la hipótesis nula aceptando que [los jugadores
zurdos obtienen mejores puntuaciones que los diestros]{.ul} para estas
variables con un [nivel de confianza del 95%]{.ul}.

# Comparación por pares

Nos preguntamos si obtendríamos el mismo resultado si **comparásemos**
los jugadores de campo zurdos con aquellos jugadores de campo diestros
que tienen un peso, altura y edad con **características similares**.
Para dar respuesta a esta pregunta, realizaremos un proceso similar al
denominado `propensity score matching`, aunque un poco simplificado.

El procedimiento se basa en calcular la **distancia euclídea** entre los
vectores de jugadores zurdos y diestros para cada una de las variables.
El resultado serán dos muestras, una primera con los jugadores zurdos, y
por cada posición de jugador, en la segunda muestra encontraremos el
jugador diestro más cercano, existiendo una relación 1 a 1 por cada
jugador de cada muestra.

## Jugador más similar

Implantamos la función euclídea que nos mostrará la distancia entre los
vectores.

```{r}
euclidean <- function( x1, x2 ){
return ( sqrt( sum ( (x1-x2)^2 ) ) )
}
```

```{r}
my.nn <- function(x, sample){
  max_row <- nrow(sample)
  #max_row <-200
  n_col <- 3
  i <- max_row
  # pos es un vector que guarda la posición y la media calculada
  # La distancia más pequeña es 0.
  # Se inicializa a un valor elevado.
  pos <- c(0, 10000)
  
  while (i > 0){
    eu <- euclidean(x, sample[i, ])
    if (eu < pos[2]){
      pos <- c(i, eu)
    }
    i <- i -1
  }
  # Return the position of the second dataframe
  return(pos[1])
}
# For testing purpose
  #my.nn(left_gamers[1, 2:4], right_gamers[, 2:4])
```

```{r}
my.nn.sample <- function( sample1, sample2, id_vector){
   max_row <- nrow(sample1)
   
  # Right.paired continene el listado de las posiciones de los jugadores diestros más similares a los zurdos.
  right.vector <-c()
  i <- max_row
  while (i > 0){
    pos <- c()
    if (i%%10 == 0){
      print(paste('# de elementos restantes: ', i))
    }
    # Escogemos el vector de sample1 y buscamos el más cercano en sample2
    pos <- my.nn(sample1[i,], sample2[, ])
    # Con la posición, buscamos el identificador del jugador
    right.vector <-c(right.vector, id_vector[pos])
    i <- i -1
  }
  print('Proceso Finalizado')
  return(right.vector)
}

```

Vamos a preparar las muestras

```{r}
column_names <- c('ID', 'Weight', 'Height', 'Age')
left_gamers <- fifa.df %>% filter(Club_Position!='GK' & Preffered_Foot=='Left') %>% select(all_of(column_names))
right_gamers <- fifa.df %>% filter(Club_Position!='GK' & Preffered_Foot=='Right') %>% select(all_of(column_names))
print(paste('# jugadores zurdos: ', nrow(left_gamers)))
print(paste('# jugadores diestros: ', nrow(right_gamers)))
```

Vemos que hay [tres veces más jugadores diestros que zurdos]{.ul}.
Lanzamos el script.

```{r}
# right.paired es un vector que contiene los identificadores de los jugadores diestros más cercanos a los zurdos.
number_left <- 100
number_right <- 500
right.paired <- c()
right.paired  <- my.nn.sample(left_gamers[1:number_left, 2:4], right_gamers[1:number_right, 2:4], right_gamers[, 'ID'])
```

Para acortar el tiempo de cálculo se ha escogido una muestra de 100
jugadores zurdos y de 500 dentro de la población de jugadores diestros.

La dos muestras tienen que tener el mismo tamaño, dado que queremos
tener **muestras apareadas**. Vamos a comprobarlo.

```{r}
nrow(left_gamers[1:number_left,]) == length(right.paired)
```

## Muestras

Una vez finalizado el proceso de cálculo, vamos a montar el dataframe
para poder comparar los jugadores zurdos y diestros según la salida del
algoritmo.

```{r}
right.paired.df <- as.data.frame(right.paired)
right.paired.df <- right.paired.df %>% mutate(line_number = row_number())

paired.df <- left_gamers[1:number_left,] %>% mutate(line_number = row_number())
paired.df <- dplyr::inner_join(paired.df, right.paired.df)
paired.df <- dplyr::inner_join(paired.df, right_gamers, by= c("right.paired" = 'ID'))
paired.df$line_number <- NULL

names(paired.df) <-c('ID.l', 'Weight.l', 'Height.l', 'Age.l',  'ID.r', 'Weight.r', 'Height.r', 'Age.r')

head(paired.df) %>% kable() %>% kable_styling()
```

Se muestra la tabla con los primeros resultados de los jugadores zurdos
y diestros. Se ha colocado el sufijo '.l' para los zurdos y el '.r' para
los diestros.

## Hipótesis nula y alternativa

Como conservamos la misma pregunta, que en el ejercicio anterior,
exponemos la hipótesis nula como que no hay diferencias por el hecho de
ser diestros o zurdos y la hipótesis alternativa como aquella en la que
los zurdos consiguen mejor puntuación en las tres variables.

Matemáticamente:

$$
\left\{
\begin{array}{ll}
H_{0}: &  \mu_{left} = \mu_{right}\\
H_{1}: & \mu_{left} > \mu_{right}
\end{array}
\right.
$$

Para cada una de las tres variables observadas, Rating, Ball control y
Dribbling, y dentro del intervalo de confianza (NC) del 95 %, pero
teniendo en cuenta que trabajaremos con las diferencias entre las
variables, tal y como se explica a continuación (contraste sobre la
media unilateral por la derecha).

## Método

Tal y como hemos ido viendo, vamos a realizar una **comparación de dos
muestra apareadas sobre la media**.

## Cálculos

En este tipo de contraste, en el que las muestras están vinculadas 1 a
1, calculamos las diferencias entre ellas, reduciendo el problema a un
contraste de una muestra con las diferencias de los dos jugadores.

```{r}
paired.df.sub <- paired.df %>% mutate(Weight =Weight.r - Weight.l) %>% mutate(Height =Height.r - Height.l)  %>% mutate(Age =Age.r - Age.l) %>% select(Weight, Height, Age)
head(paired.df.sub)
```

La asunción de la normalidad ya la demostramos en anteriormente. Así que
podemos aplicar directamente el estadístico.

```{r}
t_2_sample_by_dif <- function(df, column_name, NC){
  # El intervalo de confianza es dado (95% por defecto)

  alpha <- 1-NC
  
  # Cálculo del valor crítico
  vc <- qnorm(alpha)
  
  # Cálculo de la media de las diferencias
  mean_dif <- mean(df[, column_name])
  
  # Cálculo de la Desviación estándar
  sd_dif <- sd(df[, column_name])
  
  # Número de muestras
  n <- length(df[, column_name])

  # Cálculo del estimador
  t <- mean_dif / (sd_dif / sqrt(n))
  
  # Resultado
  return(c(column_name, t, abs(vc)))
}
column_names <- c('Weight', 'Height', 'Age')
t2_sample_table <- data.frame(matrix(ncol=3, nrow = 0))
for (col in column_names){
  out <- t_2_sample_by_dif(paired.df.sub, col, 0.95)
  t2_sample_table <- rbind(t2_sample_table, out)
}
names(t2_sample_table) <- c("Variable", "t-valor", "valor_critico")

#t2_sample_table 
```

## Interpretación

Mostremos el resultado del estimador

```{r}
t2_sample_table %>% kable() %>% kable_styling()
```

Si comparamos la salida de la anterior tabla, para las tres variables
estudiadas el valor observado (t-valor) es menor que el valor crítico

      t valor < valor crítico

lo que no permite rechazar la hipótesis nula, y por tanto [no se puede
apreciar diferencia estadística entre los jugadores y los diestros]{.ul}
para estas variables, con un [nivel de confianza del 95%]{.ul}.

## Reflexión

En este estudio hemos comparado las muestras entre jugadores 1 a 1,
buscando jugadores con características parecidas en las variables de
peso, altura y edad. En comparación con el estudio anterior, en el que
comparábamos diferencias entre en cuanto a nivel de juego, en este caso
[comparamos jugadores con identidades morfológicas parecidas]{.ul}. Es
lógico pensar, que la solución no diga que no existen diferencias, lo
que nos permite extraer la conclusión de que el proceso ha sido
correctamente ejecutado.

# Comparación entre clubes

## Hipótesis nula y alternativa

## Método

## Cálculos

## Resultados e interpretación

# Resumen ejecutivo
